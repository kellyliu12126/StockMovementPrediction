{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import  keras\n",
    "import  tensorflow as  tf  \n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# split data in 80%/10%/10% train/validation/test sets\n",
    "valid_set_size_percentage = 10 \n",
    "test_set_size_percentage = 10 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 968 entries, 2015-01-02 to 2018-11-08\n",
      "Data columns (total 9 columns):\n",
      "AMOpen      968 non-null float64\n",
      "AMClose     968 non-null float64\n",
      "AMHigh      968 non-null float64\n",
      "AMLow       968 non-null float64\n",
      "SPHigh      968 non-null float64\n",
      "SPLow       968 non-null float64\n",
      "SPClose     968 non-null float64\n",
      "SPVolume    968 non-null int64\n",
      "AMVolume    968 non-null int64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 75.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMOpen</th>\n",
       "      <th>AMClose</th>\n",
       "      <th>AMHigh</th>\n",
       "      <th>AMLow</th>\n",
       "      <th>SPHigh</th>\n",
       "      <th>SPLow</th>\n",
       "      <th>SPClose</th>\n",
       "      <th>SPVolume</th>\n",
       "      <th>AMVolume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-11-02</th>\n",
       "      <td>49.020000</td>\n",
       "      <td>48.919998</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>47.029999</td>\n",
       "      <td>15222.9004</td>\n",
       "      <td>15037.2002</td>\n",
       "      <td>15119.2998</td>\n",
       "      <td>268963600</td>\n",
       "      <td>3026701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-05</th>\n",
       "      <td>48.959999</td>\n",
       "      <td>52.529999</td>\n",
       "      <td>52.779999</td>\n",
       "      <td>47.590000</td>\n",
       "      <td>15242.4004</td>\n",
       "      <td>15136.7998</td>\n",
       "      <td>15217.7002</td>\n",
       "      <td>255477900</td>\n",
       "      <td>4749101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-06</th>\n",
       "      <td>52.880001</td>\n",
       "      <td>56.139999</td>\n",
       "      <td>57.740002</td>\n",
       "      <td>51.439999</td>\n",
       "      <td>15295.2998</td>\n",
       "      <td>15220.2002</td>\n",
       "      <td>15292.7002</td>\n",
       "      <td>237092100</td>\n",
       "      <td>16835001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-07</th>\n",
       "      <td>58.150002</td>\n",
       "      <td>60.610001</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>54.090000</td>\n",
       "      <td>15392.0000</td>\n",
       "      <td>15293.2998</td>\n",
       "      <td>15369.4004</td>\n",
       "      <td>271236500</td>\n",
       "      <td>8056401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-08</th>\n",
       "      <td>58.209999</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>59.200001</td>\n",
       "      <td>55.270000</td>\n",
       "      <td>15393.0996</td>\n",
       "      <td>15293.2998</td>\n",
       "      <td>15357.5000</td>\n",
       "      <td>272717600</td>\n",
       "      <td>5178801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AMOpen    AMClose     AMHigh      AMLow      SPHigh  \\\n",
       "Date                                                                 \n",
       "2018-11-02  49.020000  48.919998  50.000000  47.029999  15222.9004   \n",
       "2018-11-05  48.959999  52.529999  52.779999  47.590000  15242.4004   \n",
       "2018-11-06  52.880001  56.139999  57.740002  51.439999  15295.2998   \n",
       "2018-11-07  58.150002  60.610001  61.250000  54.090000  15392.0000   \n",
       "2018-11-08  58.209999  56.000000  59.200001  55.270000  15393.0996   \n",
       "\n",
       "                 SPLow     SPClose   SPVolume  AMVolume  \n",
       "Date                                                     \n",
       "2018-11-02  15037.2002  15119.2998  268963600   3026701  \n",
       "2018-11-05  15136.7998  15217.7002  255477900   4749101  \n",
       "2018-11-06  15220.2002  15292.7002  237092100  16835001  \n",
       "2018-11-07  15293.2998  15369.4004  271236500   8056401  \n",
       "2018-11-08  15293.2998  15357.5000  272717600   5178801  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import all stock prices \n",
    "df = pd.read_csv(\"WWWW.csv\", index_col = 0)\n",
    "df.info()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMOpen      5.821000e+01\n",
       "AMClose     5.600000e+01\n",
       "AMHigh      5.920000e+01\n",
       "AMLow       5.527000e+01\n",
       "SPHigh      1.539310e+04\n",
       "SPLow       1.529330e+04\n",
       "SPClose     1.535750e+04\n",
       "SPVolume    2.727176e+08\n",
       "AMVolume    5.178801e+06\n",
       "Name: 2018-11-08, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMOpen</th>\n",
       "      <th>AMClose</th>\n",
       "      <th>AMHigh</th>\n",
       "      <th>AMLow</th>\n",
       "      <th>SPHigh</th>\n",
       "      <th>SPLow</th>\n",
       "      <th>SPClose</th>\n",
       "      <th>SPVolume</th>\n",
       "      <th>AMVolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>9.680000e+02</td>\n",
       "      <td>9.680000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.638678</td>\n",
       "      <td>13.638791</td>\n",
       "      <td>14.074391</td>\n",
       "      <td>13.161797</td>\n",
       "      <td>14980.104743</td>\n",
       "      <td>14858.191941</td>\n",
       "      <td>14919.920556</td>\n",
       "      <td>2.105877e+08</td>\n",
       "      <td>2.601801e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.305952</td>\n",
       "      <td>16.298493</td>\n",
       "      <td>16.928106</td>\n",
       "      <td>15.605561</td>\n",
       "      <td>998.270174</td>\n",
       "      <td>1026.268973</td>\n",
       "      <td>1009.696847</td>\n",
       "      <td>6.699353e+07</td>\n",
       "      <td>3.503775e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>11932.400400</td>\n",
       "      <td>11531.200200</td>\n",
       "      <td>11843.099600</td>\n",
       "      <td>3.785510e+07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.097500</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>14384.674800</td>\n",
       "      <td>14263.324950</td>\n",
       "      <td>14311.725100</td>\n",
       "      <td>1.739864e+08</td>\n",
       "      <td>1.278260e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.855000</td>\n",
       "      <td>7.825000</td>\n",
       "      <td>8.005000</td>\n",
       "      <td>7.720000</td>\n",
       "      <td>15187.850100</td>\n",
       "      <td>15080.450200</td>\n",
       "      <td>15143.650400</td>\n",
       "      <td>2.020530e+08</td>\n",
       "      <td>1.036351e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.782500</td>\n",
       "      <td>18.782500</td>\n",
       "      <td>19.290000</td>\n",
       "      <td>18.172500</td>\n",
       "      <td>15649.200200</td>\n",
       "      <td>15545.925050</td>\n",
       "      <td>15609.950200</td>\n",
       "      <td>2.321720e+08</td>\n",
       "      <td>3.817526e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>73.750000</td>\n",
       "      <td>76.680000</td>\n",
       "      <td>68.110001</td>\n",
       "      <td>16586.500000</td>\n",
       "      <td>16539.199200</td>\n",
       "      <td>16567.400400</td>\n",
       "      <td>8.588881e+08</td>\n",
       "      <td>2.431410e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AMOpen     AMClose      AMHigh       AMLow        SPHigh  \\\n",
       "count  968.000000  968.000000  968.000000  968.000000    968.000000   \n",
       "mean    13.638678   13.638791   14.074391   13.161797  14980.104743   \n",
       "std     16.305952   16.298493   16.928106   15.605561    998.270174   \n",
       "min      1.520000    1.510000    1.600000    1.150000  11932.400400   \n",
       "25%      2.097500    2.100000    2.120000    2.050000  14384.674800   \n",
       "50%      7.855000    7.825000    8.005000    7.720000  15187.850100   \n",
       "75%     18.782500   18.782500   19.290000   18.172500  15649.200200   \n",
       "max     76.000000   73.750000   76.680000   68.110001  16586.500000   \n",
       "\n",
       "              SPLow       SPClose      SPVolume      AMVolume  \n",
       "count    968.000000    968.000000  9.680000e+02  9.680000e+02  \n",
       "mean   14858.191941  14919.920556  2.105877e+08  2.601801e+06  \n",
       "std     1026.268973   1009.696847  6.699353e+07  3.503775e+06  \n",
       "min    11531.200200  11843.099600  3.785510e+07  1.000000e+00  \n",
       "25%    14263.324950  14311.725100  1.739864e+08  1.278260e+05  \n",
       "50%    15080.450200  15143.650400  2.020530e+08  1.036351e+06  \n",
       "75%    15545.925050  15609.950200  2.321720e+08  3.817526e+06  \n",
       "max    16539.199200  16567.400400  8.588881e+08  2.431410e+07  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAFNCAYAAACKdYHuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n55xzec+TmXPOubz3f4VLotbL8PuBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5));\n",
    "plt.subplot(1,2,1);\n",
    "plt.plot(df.AMHigh.values, color='red', label='High')\n",
    "plt.plot(df.AMClose.values, color='green', label='Close')\n",
    "plt.plot(df.AMLow.values, color='blue', label='Low')\n",
    "plt.title('stock price')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('price')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1,2,2);\n",
    "plt.plot(df.AMVolume.values, color='black', label='volume')\n",
    "plt.title('stock volume')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('volume')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Manipulate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  (771, 4, 9)\n",
      "y_train.shape =  (771, 9)\n",
      "x_valid.shape =  (96, 4, 9)\n",
      "y_valid.shape =  (96, 9)\n",
      "x_test.shape =  (96, 4, 9)\n",
      "y_test.shape =  (96, 9)\n",
      "df_stock_norm.columns.values =  ['AMOpen', 'AMClose', 'AMHigh', 'AMLow', 'SPHigh', 'SPLow', 'SPClose', 'SPVolume', 'AMVolume']\n"
     ]
    }
   ],
   "source": [
    "# function for min-max normalization of stock\n",
    "def normalize_data(df):\n",
    "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    df['AMOpen'] = min_max_scaler.fit_transform(df.AMOpen.values.reshape(-1,1))\n",
    "    df['AMHigh'] = min_max_scaler.fit_transform(df.AMHigh.values.reshape(-1,1))\n",
    "    df['AMLow'] = min_max_scaler.fit_transform(df.AMLow.values.reshape(-1,1))\n",
    "    df['AMClose'] = min_max_scaler.fit_transform(df.AMClose.values.reshape(-1,1))\n",
    "    df['SPHigh'] = min_max_scaler.fit_transform(df.AMClose.values.reshape(-1,1))\n",
    "    df['SPLow'] = min_max_scaler.fit_transform(df.AMClose.values.reshape(-1,1))\n",
    "    df['SPClose'] = min_max_scaler.fit_transform(df.AMClose.values.reshape(-1,1))\n",
    "    df['SPVolume'] = min_max_scaler.fit_transform(df.AMClose.values.reshape(-1,1))\n",
    "    df['AMVolume'] = min_max_scaler.fit_transform(df.AMClose.values.reshape(-1,1))\n",
    "    return df\n",
    "\n",
    "# function to create train, validation, test data given stock data and sequence length\n",
    "def load_data(stock, seq_len):\n",
    "    data_raw = stock.as_matrix() # convert to numpy array\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - seq_len): \n",
    "        data.append(data_raw[index: index + seq_len])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    valid_set_size = int(np.round(valid_set_size_percentage/100*data.shape[0]));  \n",
    "    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (valid_set_size + test_set_size);\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    x_valid = data[train_set_size:train_set_size+valid_set_size,:-1,:]\n",
    "    y_valid = data[train_set_size:train_set_size+valid_set_size,-1,:]\n",
    "    \n",
    "    x_test = data[train_set_size+valid_set_size:,:-1,:]\n",
    "    y_test = data[train_set_size+valid_set_size:,-1,:]\n",
    "    \n",
    "    return [x_train, y_train, x_valid, y_valid, x_test, y_test]\n",
    "\n",
    "# normalize stock\n",
    "df_stock_norm = normalize_data(df)\n",
    "\n",
    "# create train, test data\n",
    "seq_len = 5 # choose sequence length\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(df_stock_norm, seq_len)\n",
    "print('x_train.shape = ',x_train.shape) #19*3\n",
    "print('y_train.shape = ', y_train.shape) #1*3\n",
    "print('x_valid.shape = ',x_valid.shape)\n",
    "print('y_valid.shape = ', y_valid.shape)\n",
    "print('x_test.shape = ', x_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)\n",
    "\n",
    "\n",
    "cols = list(df_stock_norm.columns.values)\n",
    "print('df_stock_norm.columns.values = ', cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANUAAAEWCAYAAADxS9ItAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMaIyGALGiMpgCJj/D/ZwlfhLxfw1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFNCAYAAAC5cXZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig= plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_stock_norm.AMClose.values, color='green', label='Close')\n",
    "#plt.plot(df_stock_norm.AMLow.values, color='blue', label='Low')\n",
    "#plt.plot(df_stock_norm.AMHigh.values, color='black', label='High')\n",
    "\n",
    "plt.title('stock')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('normalized price/volume')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RNN Model and validate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 epochs: MSE train/valid = 0.064656/0.600589\n",
      "5.00 epochs: MSE train/valid = 0.000305/0.001000\n",
      "10.00 epochs: MSE train/valid = 0.000137/0.000706\n",
      "15.00 epochs: MSE train/valid = 0.000108/0.000549\n",
      "20.00 epochs: MSE train/valid = 0.000125/0.000828\n",
      "25.00 epochs: MSE train/valid = 0.000086/0.000401\n",
      "30.00 epochs: MSE train/valid = 0.000079/0.000369\n",
      "35.00 epochs: MSE train/valid = 0.000074/0.000404\n",
      "40.00 epochs: MSE train/valid = 0.000140/0.000775\n",
      "45.00 epochs: MSE train/valid = 0.000107/0.000600\n",
      "50.00 epochs: MSE train/valid = 0.000073/0.000418\n",
      "55.00 epochs: MSE train/valid = 0.000067/0.000366\n",
      "60.00 epochs: MSE train/valid = 0.000070/0.000386\n",
      "65.00 epochs: MSE train/valid = 0.000088/0.000644\n",
      "70.00 epochs: MSE train/valid = 0.000070/0.000411\n",
      "75.00 epochs: MSE train/valid = 0.000076/0.000441\n",
      "80.00 epochs: MSE train/valid = 0.000070/0.000415\n",
      "85.00 epochs: MSE train/valid = 0.000076/0.000452\n",
      "90.00 epochs: MSE train/valid = 0.000067/0.000350\n",
      "95.00 epochs: MSE train/valid = 0.000123/0.001295\n",
      "100.00 epochs: MSE train/valid = 0.000066/0.000359\n",
      "105.00 epochs: MSE train/valid = 0.000095/0.000639\n",
      "110.00 epochs: MSE train/valid = 0.000065/0.000363\n",
      "115.00 epochs: MSE train/valid = 0.000094/0.000437\n",
      "120.00 epochs: MSE train/valid = 0.000074/0.000440\n",
      "125.00 epochs: MSE train/valid = 0.000095/0.000782\n",
      "130.00 epochs: MSE train/valid = 0.000082/0.000466\n",
      "135.00 epochs: MSE train/valid = 0.000070/0.000413\n",
      "140.00 epochs: MSE train/valid = 0.000075/0.000526\n",
      "145.00 epochs: MSE train/valid = 0.000081/0.000390\n",
      "150.00 epochs: MSE train/valid = 0.000083/0.000441\n",
      "155.00 epochs: MSE train/valid = 0.000095/0.000659\n",
      "160.00 epochs: MSE train/valid = 0.000089/0.000561\n",
      "165.00 epochs: MSE train/valid = 0.000076/0.000483\n",
      "170.00 epochs: MSE train/valid = 0.000077/0.000433\n",
      "175.00 epochs: MSE train/valid = 0.000065/0.000377\n",
      "180.00 epochs: MSE train/valid = 0.000073/0.000533\n",
      "185.00 epochs: MSE train/valid = 0.000213/0.002159\n",
      "190.00 epochs: MSE train/valid = 0.000074/0.000503\n",
      "195.00 epochs: MSE train/valid = 0.000070/0.000499\n",
      "200.00 epochs: MSE train/valid = 0.000074/0.000625\n",
      "205.00 epochs: MSE train/valid = 0.000074/0.000433\n",
      "210.00 epochs: MSE train/valid = 0.000066/0.000442\n",
      "215.00 epochs: MSE train/valid = 0.000128/0.001318\n",
      "220.00 epochs: MSE train/valid = 0.000087/0.000587\n",
      "225.00 epochs: MSE train/valid = 0.000093/0.000683\n",
      "230.00 epochs: MSE train/valid = 0.000064/0.000459\n",
      "235.00 epochs: MSE train/valid = 0.000068/0.000429\n",
      "240.00 epochs: MSE train/valid = 0.000064/0.000394\n",
      "245.00 epochs: MSE train/valid = 0.000064/0.000420\n",
      "250.00 epochs: MSE train/valid = 0.000063/0.000383\n",
      "255.00 epochs: MSE train/valid = 0.000064/0.000401\n",
      "260.00 epochs: MSE train/valid = 0.000068/0.000376\n",
      "265.00 epochs: MSE train/valid = 0.000066/0.000544\n",
      "270.00 epochs: MSE train/valid = 0.000076/0.000496\n",
      "275.00 epochs: MSE train/valid = 0.000061/0.000387\n",
      "280.00 epochs: MSE train/valid = 0.000103/0.000436\n",
      "285.00 epochs: MSE train/valid = 0.000067/0.000383\n",
      "290.00 epochs: MSE train/valid = 0.000065/0.000510\n",
      "295.00 epochs: MSE train/valid = 0.000067/0.000415\n",
      "300.00 epochs: MSE train/valid = 0.000073/0.000683\n",
      "305.00 epochs: MSE train/valid = 0.000081/0.000588\n",
      "310.00 epochs: MSE train/valid = 0.000171/0.001352\n",
      "315.00 epochs: MSE train/valid = 0.000064/0.000420\n",
      "320.00 epochs: MSE train/valid = 0.000065/0.000370\n",
      "325.00 epochs: MSE train/valid = 0.000077/0.000551\n",
      "330.00 epochs: MSE train/valid = 0.000067/0.000427\n",
      "335.00 epochs: MSE train/valid = 0.000061/0.000394\n",
      "340.00 epochs: MSE train/valid = 0.000061/0.000387\n",
      "345.00 epochs: MSE train/valid = 0.000076/0.000697\n",
      "350.00 epochs: MSE train/valid = 0.000083/0.000810\n",
      "355.00 epochs: MSE train/valid = 0.000081/0.000659\n",
      "360.00 epochs: MSE train/valid = 0.000093/0.000997\n",
      "365.00 epochs: MSE train/valid = 0.000074/0.000548\n",
      "370.00 epochs: MSE train/valid = 0.000059/0.000397\n",
      "375.00 epochs: MSE train/valid = 0.000100/0.000940\n",
      "380.00 epochs: MSE train/valid = 0.000064/0.000374\n",
      "385.00 epochs: MSE train/valid = 0.000062/0.000430\n",
      "390.00 epochs: MSE train/valid = 0.000064/0.000453\n",
      "395.00 epochs: MSE train/valid = 0.000063/0.000523\n",
      "400.00 epochs: MSE train/valid = 0.000070/0.000506\n",
      "405.00 epochs: MSE train/valid = 0.000086/0.000559\n",
      "410.00 epochs: MSE train/valid = 0.000060/0.000410\n",
      "415.00 epochs: MSE train/valid = 0.000061/0.000426\n",
      "420.00 epochs: MSE train/valid = 0.000063/0.000543\n",
      "425.00 epochs: MSE train/valid = 0.000076/0.000685\n",
      "430.00 epochs: MSE train/valid = 0.000063/0.000426\n",
      "435.00 epochs: MSE train/valid = 0.000113/0.000490\n",
      "440.00 epochs: MSE train/valid = 0.000069/0.000592\n",
      "445.00 epochs: MSE train/valid = 0.000109/0.000717\n",
      "450.00 epochs: MSE train/valid = 0.000068/0.000419\n",
      "455.00 epochs: MSE train/valid = 0.000060/0.000449\n",
      "460.00 epochs: MSE train/valid = 0.000061/0.000414\n",
      "465.00 epochs: MSE train/valid = 0.000057/0.000468\n",
      "470.00 epochs: MSE train/valid = 0.000060/0.000509\n",
      "475.00 epochs: MSE train/valid = 0.000073/0.000577\n",
      "480.00 epochs: MSE train/valid = 0.000061/0.000567\n",
      "485.00 epochs: MSE train/valid = 0.000068/0.000561\n",
      "490.00 epochs: MSE train/valid = 0.000095/0.000451\n",
      "495.00 epochs: MSE train/valid = 0.000066/0.000422\n",
      "500.00 epochs: MSE train/valid = 0.000055/0.000412\n",
      "505.00 epochs: MSE train/valid = 0.000061/0.000463\n",
      "510.00 epochs: MSE train/valid = 0.000065/0.000471\n",
      "515.00 epochs: MSE train/valid = 0.000069/0.000483\n",
      "520.00 epochs: MSE train/valid = 0.000060/0.000547\n",
      "525.00 epochs: MSE train/valid = 0.000082/0.000748\n",
      "530.00 epochs: MSE train/valid = 0.000075/0.000499\n",
      "535.00 epochs: MSE train/valid = 0.000060/0.000471\n",
      "540.00 epochs: MSE train/valid = 0.000073/0.000515\n",
      "545.00 epochs: MSE train/valid = 0.000059/0.000482\n",
      "550.00 epochs: MSE train/valid = 0.000056/0.000493\n",
      "555.00 epochs: MSE train/valid = 0.000080/0.001142\n",
      "560.00 epochs: MSE train/valid = 0.000057/0.000496\n",
      "565.00 epochs: MSE train/valid = 0.000122/0.000642\n",
      "570.00 epochs: MSE train/valid = 0.000081/0.000626\n",
      "575.00 epochs: MSE train/valid = 0.000060/0.000560\n",
      "580.00 epochs: MSE train/valid = 0.000066/0.000665\n",
      "585.00 epochs: MSE train/valid = 0.000071/0.000703\n",
      "590.00 epochs: MSE train/valid = 0.000068/0.000788\n",
      "595.00 epochs: MSE train/valid = 0.000072/0.000529\n",
      "600.00 epochs: MSE train/valid = 0.000065/0.000476\n",
      "605.00 epochs: MSE train/valid = 0.000062/0.000488\n",
      "610.00 epochs: MSE train/valid = 0.000059/0.000534\n",
      "615.00 epochs: MSE train/valid = 0.000052/0.000475\n",
      "620.00 epochs: MSE train/valid = 0.000074/0.000808\n",
      "625.00 epochs: MSE train/valid = 0.000059/0.000494\n",
      "630.00 epochs: MSE train/valid = 0.000062/0.000559\n",
      "635.00 epochs: MSE train/valid = 0.000052/0.000519\n",
      "640.00 epochs: MSE train/valid = 0.000057/0.000512\n",
      "645.00 epochs: MSE train/valid = 0.000060/0.000602\n",
      "650.00 epochs: MSE train/valid = 0.000054/0.000519\n",
      "655.00 epochs: MSE train/valid = 0.000063/0.000536\n",
      "660.00 epochs: MSE train/valid = 0.000054/0.000487\n",
      "665.00 epochs: MSE train/valid = 0.000052/0.000515\n",
      "670.00 epochs: MSE train/valid = 0.000064/0.000679\n",
      "675.00 epochs: MSE train/valid = 0.000068/0.000596\n",
      "680.00 epochs: MSE train/valid = 0.000069/0.000598\n",
      "685.00 epochs: MSE train/valid = 0.000098/0.000983\n",
      "690.00 epochs: MSE train/valid = 0.000082/0.000548\n",
      "695.00 epochs: MSE train/valid = 0.000075/0.000721\n",
      "700.00 epochs: MSE train/valid = 0.000065/0.000531\n",
      "705.00 epochs: MSE train/valid = 0.000060/0.000540\n",
      "710.00 epochs: MSE train/valid = 0.000059/0.000664\n",
      "715.00 epochs: MSE train/valid = 0.000066/0.000759\n",
      "720.00 epochs: MSE train/valid = 0.000055/0.000524\n",
      "725.00 epochs: MSE train/valid = 0.000060/0.000652\n",
      "730.00 epochs: MSE train/valid = 0.000114/0.000692\n",
      "735.00 epochs: MSE train/valid = 0.000053/0.000504\n",
      "740.00 epochs: MSE train/valid = 0.000052/0.000559\n",
      "745.00 epochs: MSE train/valid = 0.000079/0.000970\n",
      "750.00 epochs: MSE train/valid = 0.000057/0.000548\n",
      "755.00 epochs: MSE train/valid = 0.000055/0.000599\n",
      "760.00 epochs: MSE train/valid = 0.000063/0.000635\n",
      "765.00 epochs: MSE train/valid = 0.000055/0.000547\n",
      "770.00 epochs: MSE train/valid = 0.000103/0.001040\n",
      "775.00 epochs: MSE train/valid = 0.000057/0.000543\n",
      "780.00 epochs: MSE train/valid = 0.000073/0.000545\n",
      "785.00 epochs: MSE train/valid = 0.000058/0.000515\n",
      "790.00 epochs: MSE train/valid = 0.000070/0.000619\n",
      "795.00 epochs: MSE train/valid = 0.000121/0.000557\n",
      "800.00 epochs: MSE train/valid = 0.000064/0.000619\n",
      "805.00 epochs: MSE train/valid = 0.000106/0.000621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810.00 epochs: MSE train/valid = 0.000062/0.000742\n",
      "815.00 epochs: MSE train/valid = 0.000081/0.001137\n",
      "820.00 epochs: MSE train/valid = 0.000081/0.001109\n",
      "825.00 epochs: MSE train/valid = 0.000057/0.000515\n",
      "830.00 epochs: MSE train/valid = 0.000051/0.000519\n",
      "835.00 epochs: MSE train/valid = 0.000068/0.000982\n",
      "840.00 epochs: MSE train/valid = 0.000060/0.000563\n",
      "845.00 epochs: MSE train/valid = 0.000056/0.000536\n",
      "850.00 epochs: MSE train/valid = 0.000054/0.000531\n",
      "855.00 epochs: MSE train/valid = 0.000055/0.000623\n",
      "860.00 epochs: MSE train/valid = 0.000059/0.000593\n",
      "865.00 epochs: MSE train/valid = 0.000072/0.000826\n",
      "870.00 epochs: MSE train/valid = 0.000055/0.000559\n",
      "875.00 epochs: MSE train/valid = 0.000070/0.000896\n",
      "880.00 epochs: MSE train/valid = 0.000054/0.000541\n",
      "885.00 epochs: MSE train/valid = 0.000061/0.000590\n",
      "890.00 epochs: MSE train/valid = 0.000067/0.000694\n",
      "895.00 epochs: MSE train/valid = 0.000056/0.000528\n",
      "900.00 epochs: MSE train/valid = 0.000056/0.000604\n",
      "905.00 epochs: MSE train/valid = 0.000057/0.000628\n",
      "910.00 epochs: MSE train/valid = 0.000068/0.000733\n",
      "915.00 epochs: MSE train/valid = 0.000059/0.000671\n",
      "920.00 epochs: MSE train/valid = 0.000068/0.000738\n",
      "925.00 epochs: MSE train/valid = 0.000068/0.000747\n",
      "930.00 epochs: MSE train/valid = 0.000065/0.000626\n",
      "935.00 epochs: MSE train/valid = 0.000063/0.000672\n",
      "940.00 epochs: MSE train/valid = 0.000060/0.000735\n",
      "945.00 epochs: MSE train/valid = 0.000062/0.000674\n",
      "950.00 epochs: MSE train/valid = 0.000052/0.000564\n",
      "955.00 epochs: MSE train/valid = 0.000069/0.000618\n",
      "960.00 epochs: MSE train/valid = 0.000063/0.000725\n",
      "965.00 epochs: MSE train/valid = 0.000078/0.000613\n",
      "970.00 epochs: MSE train/valid = 0.000055/0.000629\n",
      "975.00 epochs: MSE train/valid = 0.000050/0.000558\n",
      "980.00 epochs: MSE train/valid = 0.000055/0.000581\n",
      "985.00 epochs: MSE train/valid = 0.000053/0.000512\n",
      "990.00 epochs: MSE train/valid = 0.000059/0.000589\n",
      "995.00 epochs: MSE train/valid = 0.000080/0.000546\n"
     ]
    }
   ],
   "source": [
    "## Basic Cell RNN in tensorflow\n",
    "\n",
    "index_in_epoch = 0;\n",
    "perm_array  = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(perm_array)\n",
    "\n",
    "# function to get the next batch\n",
    "def get_next_batch(batch_size):\n",
    "    global index_in_epoch, x_train, perm_array   \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > x_train.shape[0]:\n",
    "        np.random.shuffle(perm_array) # shuffle permutation array\n",
    "        start = 0 # start next epoch\n",
    "        index_in_epoch = batch_size\n",
    "        \n",
    "    end = index_in_epoch\n",
    "    return x_train[perm_array[start:end]], y_train[perm_array[start:end]]\n",
    "\n",
    "# parameters\n",
    "n_steps = seq_len-1 \n",
    "n_inputs = 9\n",
    "n_neurons = 3 \n",
    "n_outputs = 9\n",
    "n_layers = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "n_epochs = 1000\n",
    "train_set_size = x_train.shape[0]\n",
    "test_set_size = x_test.shape[0]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_outputs])\n",
    "\n",
    "# use Basic RNN Cell\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "          for layer in range(n_layers)]\n",
    "                                                             \n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) \n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "outputs = outputs[:,n_steps-1,:] # keep only last output of sequence\n",
    "                                              \n",
    "loss = tf.reduce_mean(tf.square(outputs - y)) # loss function = mean squared error \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n",
    "training_op = optimizer.minimize(loss)\n",
    "                                              \n",
    "# run graph\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for iteration in range(int(n_epochs*train_set_size/batch_size)):\n",
    "        x_batch, y_batch = get_next_batch(batch_size) # fetch the next training batch \n",
    "        sess.run(training_op, feed_dict={X: x_batch, y: y_batch}) \n",
    "        if iteration % int(5*train_set_size/batch_size) == 0:\n",
    "            mse_train = loss.eval(feed_dict={X: x_train, y: y_train}) \n",
    "            mse_valid = loss.eval(feed_dict={X: x_valid, y: y_valid}) \n",
    "            print('%.2f epochs: MSE train/valid = %.6f/%.6f'%(\n",
    "                iteration*batch_size/train_set_size, mse_train, mse_valid))\n",
    "\n",
    "    y_train_pred = sess.run(outputs, feed_dict={X: x_train})\n",
    "    y_valid_pred = sess.run(outputs, feed_dict={X: x_valid})\n",
    "    y_test_pred = sess.run(outputs, feed_dict={X: x_test})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RNN Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ft = 1 # 0 =highest, 1= lowest,  2 = close\n",
    "\n",
    "## show predictions\n",
    "figRNNPredict=plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]), y_train[:,ft], color='blue', label='RNN train target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_valid.shape[0]), y_valid[:,ft],\n",
    "         color='gray', label='RNN valid target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]+y_valid.shape[0],\n",
    "                   y_train.shape[0]+y_test.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='RNN test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]),y_train_pred[:,ft], color='red',\n",
    "         label='train prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_valid_pred.shape[0]),\n",
    "         y_valid_pred[:,ft], color='orange', label='RNN valid prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]+y_valid_pred.shape[0],\n",
    "                   y_train_pred.shape[0]+y_valid_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='RNN test prediction')\n",
    "\n",
    "\n",
    "plt.title('past and future stock prices')\n",
    "plt.xlabel('Days (2015.01.02 ~ 2018.01.29)')\n",
    "plt.ylabel('normalized CGC stock price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='RNN test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='RNN test prediction')\n",
    "\n",
    "plt.title('future CGC stock prices')\n",
    "plt.xlabel('Days (from 2018.06.16 ~ 2018.11.08)')\n",
    "plt.ylabel('normalized CGC stock price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "figRNNPredict.savefig('figRNNredict.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate RNN Corr sign, MSE, RMSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct sign prediction for current close - previous close price for train/valid/test: 0.74/0.80/0.75\n"
     ]
    }
   ],
   "source": [
    "## Return= close yt+1 - close yt\n",
    "y_train_Close= y_train[:,0]\n",
    "y_train_pred_Close= y_train_pred[:,0]\n",
    "\n",
    "y_valid_Close= y_valid[:,0]\n",
    "y_valid_pred_Close= y_valid_pred[:,0]\n",
    "\n",
    "\n",
    "y_test_Close= y_test[:,0]\n",
    "y_test_pred_Close= y_test_pred[:,0]\n",
    "\n",
    "\n",
    "corr_price_development_train = np.sum(np.equal(np.sign(y_train_Close[1:]-y_train_Close[:-1]),\n",
    "            np.sign(y_train_pred_Close[1:]-y_train_pred_Close[:-1] )).astype(int)) / y_train.shape[0]\n",
    "\n",
    "corr_price_development_valid = np.sum(np.equal(np.sign(y_valid_Close[1:]-y_valid_Close[:-1]),\n",
    "            np.sign(y_valid_pred_Close[1:]-y_valid_pred_Close[:-1] )).astype(int)) / y_valid.shape[0]\n",
    "\n",
    "corr_price_development_test = np.sum(np.equal(np.sign(y_test_Close[1:]-y_test_Close[:-1]),\n",
    "            np.sign(y_test_pred_Close[1:]-y_test_pred_Close[:-1])).astype(int)) / y_test.shape[0]\n",
    "\n",
    "                                             \n",
    "print('correct sign prediction for current close - previous close price for train/valid/test: %.2f/%.2f/%.2f'%(\n",
    "    corr_price_development_train, corr_price_development_valid, corr_price_development_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN train MSE =  2.907645155895717e-05\n",
      "RNN train RMSE =  0.00539225848406372\n",
      "RNN train MAE =  0.0036247297321064876\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#RNN train\n",
    "error = []\n",
    "for i in range(len(y_train_Close)):\n",
    "    error.append(y_train_Close[i] - y_train_pred_Close[i])\n",
    " \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val)\n",
    "    absError.append(abs(val))\n",
    " \n",
    "print(\"RNN train MSE = \", sum(squaredError) / len(squaredError))\n",
    "from math import sqrt\n",
    "print(\"RNN train RMSE = \", sqrt(sum(squaredError) / len(squaredError)))\n",
    "print(\"RNN train MAE = \", sum(absError) / len(absError))\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_train_Close, y_train_pred_Close): \n",
    "    y_train_Close, y_train_pred_Close = np.array(y_train_Close), np.array(y_train_pred_Close)\n",
    "    return np.mean(np.abs((y_train_Close - y_train_pred_Close) / y_train_pred_Close)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(y_train_Close, y_train_pred_Close)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN valid MSE =  0.0003026122822313553\n",
      "RNN valid RMSE =  0.017395754718647745\n",
      "RNN valid MAE =  0.01317841229639276\n"
     ]
    }
   ],
   "source": [
    "# RNN valid\n",
    "error = []\n",
    "for i in range(len(y_valid_Close)):\n",
    "    error.append(y_valid_Close[i] - y_valid_pred_Close[i])\n",
    " \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val)\n",
    "    absError.append(abs(val))\n",
    " \n",
    "print(\"RNN valid MSE = \", sum(squaredError) / len(squaredError))\n",
    "from math import sqrt\n",
    "print(\"RNN valid RMSE = \", sqrt(sum(squaredError) / len(squaredError)))\n",
    "print(\"RNN valid MAE = \", sum(absError) / len(absError))\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_valid_Close, y_valid_pred_Close): \n",
    "    y_valid_Close, y_valid_pred_Close = np.array(y_valid_Close), np.array(y_valid_pred_Close)\n",
    "    return np.mean(np.abs((y_valid_Close - y_valid_pred_Close) / y_valid_pred_Close)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(y_valid_Close, y_valid_pred_Close)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN test MSE =  0.015666174365799465\n",
      "RNN test RMSE =  0.12516458910490405\n",
      "RNN testMAE =  0.09607945411954187\n"
     ]
    }
   ],
   "source": [
    "# RNN test \n",
    "error = []\n",
    "for i in range(len(y_test_Close)):\n",
    "    error.append(y_test_Close[i] - y_test_pred_Close[i])\n",
    " \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val)\n",
    "    absError.append(abs(val))\n",
    "      \n",
    "print(\"RNN test MSE = \", sum(squaredError) / len(squaredError))\n",
    "from math import sqrt\n",
    "print(\"RNN test RMSE = \", sqrt(sum(squaredError) / len(squaredError)))\n",
    "print(\"RNN testMAE = \", sum(absError) / len(absError))\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_test_Close, y_test_pred_Close): \n",
    "    y_test_Close, y_test_pred_Close = np.array(y_test_Close), np.array(y_test_pred_Close)\n",
    "    return np.mean(np.abs((y_test_Close - y_test_pred_Close) / y_test_pred_Close)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(y_test_Close, y_test_pred_Close)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py:513: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "def action_list(y_test_pred_Close):    \n",
    "    a=[]\n",
    "    i=1\n",
    "    for i in range(96):\n",
    "        if y_test_pred_Close[i]> y_test_pred_Close[i-1]:\n",
    "            a.append(1)\n",
    "        else:\n",
    "            a.append(0)\n",
    "    return a\n",
    "\n",
    "S = action_list(y_test_pred_Close)\n",
    "#len(S)\n",
    "\n",
    "y = y_test_pred_Close *(73.75 - 1.5)+ 1.5\n",
    "Return= y *S\n",
    "#Return\n",
    "\n",
    "ReturnN=y_test_pred_Close*S\n",
    "\n",
    "figRNNReturn=plt.figure(figsize = (15,8))\n",
    "plt.plot(ReturnN.cumsum(),'-',label='RNN backtest result')\n",
    "#plt.plot(Return.cumsum(),'-',label='backtest result')\n",
    "plt.grid(1)\n",
    "\n",
    "plt.title('future stock acumulative return')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('denormalized CGC stock price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "figRNNReturn.savefig('RNNReturn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.58161932,  0.58161932,  0.58161932,  0.58161932,\n",
       "        0.58161932,  1.08721209,  1.08721209,  1.56394655,  1.56394655,\n",
       "        2.05039668,  2.05039668,  2.05039668,  2.05039668,  2.5293313 ,\n",
       "        2.5293313 ,  2.5293313 ,  2.5293313 ,  2.5293313 ,  2.96353871,\n",
       "        2.96353871,  2.96353871,  3.38970235,  3.38970235,  3.80892459,\n",
       "        3.80892459,  4.22963673,  4.65325066,  5.08113328,  5.08113328,\n",
       "        5.51188341,  5.51188341,  5.93987367,  6.38845974,  6.8511844 ,\n",
       "        6.8511844 ,  6.8511844 ,  6.8511844 ,  7.39007697,  7.39007697,\n",
       "        7.9520292 ,  8.54797837,  9.15372011,  9.78102276, 10.42463747,\n",
       "       11.11942104, 11.81714806, 11.81714806, 12.51212892, 12.51212892,\n",
       "       13.2065427 , 14.01616666, 14.01616666, 14.01616666, 14.78436074,\n",
       "       14.78436074, 14.78436074, 14.78436074, 14.78436074, 15.50340781,\n",
       "       15.50340781, 16.28637508, 16.28637508, 17.06429359, 17.06429359,\n",
       "       17.85171935, 17.85171935, 18.61823586, 18.61823586, 18.61823586,\n",
       "       18.61823586, 18.61823586, 19.34930977, 19.34930977, 20.05621144,\n",
       "       20.77264926, 20.77264926, 20.77264926, 21.51649794, 22.37687793,\n",
       "       22.37687793, 22.37687793, 22.37687793, 22.37687793, 22.37687793,\n",
       "       22.99493828, 22.99493828, 23.60444787, 23.60444787, 23.60444787,\n",
       "       24.13549343, 24.70873562, 25.28543332, 25.87118605, 26.49984011,\n",
       "       27.16874835])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReturnN.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 LSTM Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 epochs: MSE train/valid = 0.014607/0.178401\n",
      "5.00 epochs: MSE train/valid = 0.000176/0.001280\n",
      "10.00 epochs: MSE train/valid = 0.000165/0.001192\n",
      "15.00 epochs: MSE train/valid = 0.000176/0.001428\n",
      "20.00 epochs: MSE train/valid = 0.000164/0.001511\n",
      "25.00 epochs: MSE train/valid = 0.000131/0.001061\n",
      "30.00 epochs: MSE train/valid = 0.000132/0.001417\n",
      "35.00 epochs: MSE train/valid = 0.000119/0.000920\n",
      "40.00 epochs: MSE train/valid = 0.000159/0.001517\n",
      "45.00 epochs: MSE train/valid = 0.000085/0.000819\n",
      "50.00 epochs: MSE train/valid = 0.000127/0.001700\n",
      "55.00 epochs: MSE train/valid = 0.000072/0.000674\n",
      "60.00 epochs: MSE train/valid = 0.000065/0.000591\n",
      "65.00 epochs: MSE train/valid = 0.000138/0.001546\n",
      "70.00 epochs: MSE train/valid = 0.000067/0.000629\n",
      "75.00 epochs: MSE train/valid = 0.000093/0.001013\n",
      "80.00 epochs: MSE train/valid = 0.000067/0.000594\n",
      "85.00 epochs: MSE train/valid = 0.000074/0.000779\n",
      "90.00 epochs: MSE train/valid = 0.000068/0.000521\n",
      "95.00 epochs: MSE train/valid = 0.000088/0.000788\n",
      "100.00 epochs: MSE train/valid = 0.000070/0.000535\n",
      "105.00 epochs: MSE train/valid = 0.000084/0.000993\n",
      "110.00 epochs: MSE train/valid = 0.000071/0.000663\n",
      "115.00 epochs: MSE train/valid = 0.000065/0.000607\n",
      "120.00 epochs: MSE train/valid = 0.000090/0.001100\n",
      "125.00 epochs: MSE train/valid = 0.000066/0.000467\n",
      "130.00 epochs: MSE train/valid = 0.000071/0.000581\n",
      "135.00 epochs: MSE train/valid = 0.000066/0.000645\n",
      "140.00 epochs: MSE train/valid = 0.000059/0.000465\n",
      "145.00 epochs: MSE train/valid = 0.000065/0.000565\n",
      "150.00 epochs: MSE train/valid = 0.000072/0.000721\n",
      "155.00 epochs: MSE train/valid = 0.000061/0.000613\n",
      "160.00 epochs: MSE train/valid = 0.000080/0.001086\n",
      "165.00 epochs: MSE train/valid = 0.000068/0.000529\n",
      "170.00 epochs: MSE train/valid = 0.000068/0.000750\n",
      "175.00 epochs: MSE train/valid = 0.000088/0.000771\n",
      "180.00 epochs: MSE train/valid = 0.000074/0.000627\n",
      "185.00 epochs: MSE train/valid = 0.000065/0.000544\n",
      "190.00 epochs: MSE train/valid = 0.000068/0.000504\n",
      "195.00 epochs: MSE train/valid = 0.000081/0.001117\n",
      "200.00 epochs: MSE train/valid = 0.000066/0.000477\n",
      "205.00 epochs: MSE train/valid = 0.000068/0.000837\n",
      "210.00 epochs: MSE train/valid = 0.000064/0.000612\n",
      "215.00 epochs: MSE train/valid = 0.000058/0.000696\n",
      "220.00 epochs: MSE train/valid = 0.000073/0.000950\n",
      "225.00 epochs: MSE train/valid = 0.000056/0.000573\n",
      "230.00 epochs: MSE train/valid = 0.000110/0.001377\n",
      "235.00 epochs: MSE train/valid = 0.000061/0.000728\n",
      "240.00 epochs: MSE train/valid = 0.000066/0.000807\n",
      "245.00 epochs: MSE train/valid = 0.000099/0.000931\n",
      "250.00 epochs: MSE train/valid = 0.000057/0.000539\n",
      "255.00 epochs: MSE train/valid = 0.000063/0.000653\n",
      "260.00 epochs: MSE train/valid = 0.000061/0.000501\n",
      "265.00 epochs: MSE train/valid = 0.000062/0.000428\n",
      "270.00 epochs: MSE train/valid = 0.000061/0.000658\n",
      "275.00 epochs: MSE train/valid = 0.000070/0.000690\n",
      "280.00 epochs: MSE train/valid = 0.000060/0.000643\n",
      "285.00 epochs: MSE train/valid = 0.000073/0.001123\n",
      "290.00 epochs: MSE train/valid = 0.000063/0.000550\n",
      "295.00 epochs: MSE train/valid = 0.000063/0.000552\n",
      "300.00 epochs: MSE train/valid = 0.000059/0.000776\n",
      "305.00 epochs: MSE train/valid = 0.000055/0.000585\n",
      "310.00 epochs: MSE train/valid = 0.000064/0.000695\n",
      "315.00 epochs: MSE train/valid = 0.000058/0.000680\n",
      "320.00 epochs: MSE train/valid = 0.000064/0.000811\n",
      "325.00 epochs: MSE train/valid = 0.000055/0.000595\n",
      "330.00 epochs: MSE train/valid = 0.000058/0.000566\n",
      "335.00 epochs: MSE train/valid = 0.000077/0.000856\n",
      "340.00 epochs: MSE train/valid = 0.000069/0.000713\n",
      "345.00 epochs: MSE train/valid = 0.000079/0.001036\n",
      "350.00 epochs: MSE train/valid = 0.000061/0.000936\n",
      "355.00 epochs: MSE train/valid = 0.000062/0.000700\n",
      "360.00 epochs: MSE train/valid = 0.000055/0.000589\n",
      "365.00 epochs: MSE train/valid = 0.000058/0.000823\n",
      "370.00 epochs: MSE train/valid = 0.000059/0.000945\n",
      "375.00 epochs: MSE train/valid = 0.000062/0.000769\n",
      "380.00 epochs: MSE train/valid = 0.000065/0.000623\n",
      "385.00 epochs: MSE train/valid = 0.000059/0.000724\n",
      "390.00 epochs: MSE train/valid = 0.000073/0.000687\n",
      "395.00 epochs: MSE train/valid = 0.000060/0.000472\n",
      "400.00 epochs: MSE train/valid = 0.000056/0.000833\n",
      "405.00 epochs: MSE train/valid = 0.000064/0.000692\n",
      "410.00 epochs: MSE train/valid = 0.000057/0.000576\n",
      "415.00 epochs: MSE train/valid = 0.000060/0.000493\n",
      "420.00 epochs: MSE train/valid = 0.000058/0.000647\n",
      "425.00 epochs: MSE train/valid = 0.000057/0.000687\n",
      "430.00 epochs: MSE train/valid = 0.000055/0.000589\n",
      "435.00 epochs: MSE train/valid = 0.000054/0.000607\n",
      "440.00 epochs: MSE train/valid = 0.000054/0.000509\n",
      "445.00 epochs: MSE train/valid = 0.000062/0.000625\n",
      "450.00 epochs: MSE train/valid = 0.000059/0.000636\n",
      "455.00 epochs: MSE train/valid = 0.000068/0.000963\n",
      "460.00 epochs: MSE train/valid = 0.000066/0.000683\n",
      "465.00 epochs: MSE train/valid = 0.000054/0.000481\n",
      "470.00 epochs: MSE train/valid = 0.000058/0.000500\n",
      "475.00 epochs: MSE train/valid = 0.000057/0.000698\n",
      "480.00 epochs: MSE train/valid = 0.000053/0.000656\n",
      "485.00 epochs: MSE train/valid = 0.000077/0.000845\n",
      "490.00 epochs: MSE train/valid = 0.000058/0.000575\n",
      "495.00 epochs: MSE train/valid = 0.000066/0.000779\n",
      "500.00 epochs: MSE train/valid = 0.000061/0.000807\n",
      "505.00 epochs: MSE train/valid = 0.000073/0.000712\n",
      "510.00 epochs: MSE train/valid = 0.000057/0.000578\n",
      "515.00 epochs: MSE train/valid = 0.000054/0.000576\n",
      "520.00 epochs: MSE train/valid = 0.000071/0.000862\n",
      "525.00 epochs: MSE train/valid = 0.000050/0.000535\n",
      "530.00 epochs: MSE train/valid = 0.000055/0.000528\n",
      "535.00 epochs: MSE train/valid = 0.000053/0.000624\n",
      "540.00 epochs: MSE train/valid = 0.000059/0.000785\n",
      "545.00 epochs: MSE train/valid = 0.000058/0.000644\n",
      "550.00 epochs: MSE train/valid = 0.000055/0.000670\n",
      "555.00 epochs: MSE train/valid = 0.000059/0.000533\n",
      "560.00 epochs: MSE train/valid = 0.000051/0.000547\n",
      "565.00 epochs: MSE train/valid = 0.000054/0.000504\n",
      "570.00 epochs: MSE train/valid = 0.000084/0.000643\n",
      "575.00 epochs: MSE train/valid = 0.000056/0.000550\n",
      "580.00 epochs: MSE train/valid = 0.000048/0.000573\n",
      "585.00 epochs: MSE train/valid = 0.000069/0.000477\n",
      "590.00 epochs: MSE train/valid = 0.000050/0.000541\n",
      "595.00 epochs: MSE train/valid = 0.000057/0.000603\n",
      "600.00 epochs: MSE train/valid = 0.000058/0.000677\n",
      "605.00 epochs: MSE train/valid = 0.000053/0.000571\n",
      "610.00 epochs: MSE train/valid = 0.000052/0.000525\n",
      "615.00 epochs: MSE train/valid = 0.000071/0.000963\n",
      "620.00 epochs: MSE train/valid = 0.000052/0.000552\n",
      "625.00 epochs: MSE train/valid = 0.000051/0.000560\n",
      "630.00 epochs: MSE train/valid = 0.000095/0.001061\n",
      "635.00 epochs: MSE train/valid = 0.000051/0.000632\n",
      "640.00 epochs: MSE train/valid = 0.000053/0.000618\n",
      "645.00 epochs: MSE train/valid = 0.000054/0.000550\n",
      "650.00 epochs: MSE train/valid = 0.000064/0.000698\n",
      "655.00 epochs: MSE train/valid = 0.000063/0.000988\n",
      "660.00 epochs: MSE train/valid = 0.000073/0.000589\n",
      "665.00 epochs: MSE train/valid = 0.000093/0.001259\n",
      "670.00 epochs: MSE train/valid = 0.000054/0.000536\n",
      "675.00 epochs: MSE train/valid = 0.000062/0.000849\n",
      "680.00 epochs: MSE train/valid = 0.000058/0.000690\n",
      "685.00 epochs: MSE train/valid = 0.000049/0.000669\n",
      "690.00 epochs: MSE train/valid = 0.000051/0.000584\n",
      "695.00 epochs: MSE train/valid = 0.000054/0.000553\n",
      "700.00 epochs: MSE train/valid = 0.000067/0.000915\n",
      "705.00 epochs: MSE train/valid = 0.000046/0.000569\n",
      "710.00 epochs: MSE train/valid = 0.000055/0.000635\n",
      "715.00 epochs: MSE train/valid = 0.000045/0.000584\n",
      "720.00 epochs: MSE train/valid = 0.000048/0.000602\n",
      "725.00 epochs: MSE train/valid = 0.000054/0.000637\n",
      "730.00 epochs: MSE train/valid = 0.000048/0.000609\n",
      "735.00 epochs: MSE train/valid = 0.000047/0.000559\n",
      "740.00 epochs: MSE train/valid = 0.000052/0.000570\n",
      "745.00 epochs: MSE train/valid = 0.000067/0.001366\n",
      "750.00 epochs: MSE train/valid = 0.000044/0.000558\n",
      "755.00 epochs: MSE train/valid = 0.000050/0.000599\n",
      "760.00 epochs: MSE train/valid = 0.000044/0.000619\n",
      "765.00 epochs: MSE train/valid = 0.000047/0.000734\n",
      "770.00 epochs: MSE train/valid = 0.000078/0.001610\n",
      "775.00 epochs: MSE train/valid = 0.000043/0.000513\n",
      "780.00 epochs: MSE train/valid = 0.000046/0.000548\n",
      "785.00 epochs: MSE train/valid = 0.000057/0.000868\n",
      "790.00 epochs: MSE train/valid = 0.000049/0.000534\n",
      "795.00 epochs: MSE train/valid = 0.000055/0.000994\n",
      "800.00 epochs: MSE train/valid = 0.000043/0.000607\n",
      "805.00 epochs: MSE train/valid = 0.000044/0.000652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810.00 epochs: MSE train/valid = 0.000043/0.000488\n",
      "815.00 epochs: MSE train/valid = 0.000044/0.000604\n",
      "820.00 epochs: MSE train/valid = 0.000047/0.000697\n",
      "825.00 epochs: MSE train/valid = 0.000071/0.001165\n",
      "830.00 epochs: MSE train/valid = 0.000072/0.001179\n",
      "835.00 epochs: MSE train/valid = 0.000049/0.000613\n",
      "840.00 epochs: MSE train/valid = 0.000053/0.000905\n",
      "845.00 epochs: MSE train/valid = 0.000046/0.000849\n",
      "850.00 epochs: MSE train/valid = 0.000049/0.000631\n",
      "855.00 epochs: MSE train/valid = 0.000048/0.000724\n",
      "860.00 epochs: MSE train/valid = 0.000053/0.000725\n",
      "865.00 epochs: MSE train/valid = 0.000049/0.000901\n",
      "870.00 epochs: MSE train/valid = 0.000042/0.000717\n",
      "875.00 epochs: MSE train/valid = 0.000053/0.001199\n",
      "880.00 epochs: MSE train/valid = 0.000044/0.000866\n",
      "885.00 epochs: MSE train/valid = 0.000048/0.000942\n",
      "890.00 epochs: MSE train/valid = 0.000049/0.000902\n",
      "895.00 epochs: MSE train/valid = 0.000065/0.000839\n",
      "900.00 epochs: MSE train/valid = 0.000049/0.000750\n",
      "905.00 epochs: MSE train/valid = 0.000046/0.001028\n",
      "910.00 epochs: MSE train/valid = 0.000045/0.000777\n",
      "915.00 epochs: MSE train/valid = 0.000058/0.000817\n",
      "920.00 epochs: MSE train/valid = 0.000047/0.000712\n",
      "925.00 epochs: MSE train/valid = 0.000045/0.001218\n",
      "930.00 epochs: MSE train/valid = 0.000053/0.000752\n",
      "935.00 epochs: MSE train/valid = 0.000041/0.000819\n",
      "940.00 epochs: MSE train/valid = 0.000051/0.000564\n",
      "945.00 epochs: MSE train/valid = 0.000053/0.000930\n",
      "950.00 epochs: MSE train/valid = 0.000054/0.000804\n",
      "955.00 epochs: MSE train/valid = 0.000041/0.000703\n",
      "960.00 epochs: MSE train/valid = 0.000063/0.001088\n",
      "965.00 epochs: MSE train/valid = 0.000046/0.000892\n",
      "970.00 epochs: MSE train/valid = 0.000042/0.000631\n",
      "975.00 epochs: MSE train/valid = 0.000043/0.000775\n",
      "980.00 epochs: MSE train/valid = 0.000045/0.001040\n"
     ]
    }
   ],
   "source": [
    "## Basic Cell LSTM in tensorflow\n",
    "\n",
    "index_in_epoch = 0;\n",
    "perm_array  = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(perm_array)\n",
    "\n",
    "# function to get the next batch\n",
    "def get_next_batch(batch_size):\n",
    "    global index_in_epoch, x_train, perm_array   \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > x_train.shape[0]:\n",
    "        np.random.shuffle(perm_array) # shuffle permutation array\n",
    "        start = 0 # start next epoch\n",
    "        index_in_epoch = batch_size\n",
    "        \n",
    "    end = index_in_epoch\n",
    "    return x_train[perm_array[start:end]], y_train[perm_array[start:end]]\n",
    "\n",
    "# parameters\n",
    "n_steps = seq_len-1\n",
    "n_inputs = 9 \n",
    "n_neurons = 3 \n",
    "n_outputs = 9\n",
    "n_layers = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "n_epochs = 1000 \n",
    "train_set_size = x_train.shape[0]\n",
    "test_set_size = x_test.shape[0]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_outputs])\n",
    "\n",
    "# use Basic RNN Cell\n",
    "#layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "          #for layer in range(n_layers)]\n",
    "\n",
    "# use Basic LSTM Cell \n",
    "layers = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "          for layer in range(n_layers)]\n",
    "                                                                     \n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) \n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "outputs = outputs[:,n_steps-1,:] # keep only last output of sequence\n",
    "                                              \n",
    "loss = tf.reduce_mean(tf.square(outputs - y)) # loss function = mean squared error \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n",
    "training_op = optimizer.minimize(loss)\n",
    "                                              \n",
    "# run graph\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for iteration in range(int(n_epochs*train_set_size/batch_size)):\n",
    "        x_batch, y_batch = get_next_batch(batch_size) # fetch the next training batch \n",
    "        sess.run(training_op, feed_dict={X: x_batch, y: y_batch}) \n",
    "        if iteration % int(5*train_set_size/batch_size) == 0:\n",
    "            mse_train = loss.eval(feed_dict={X: x_train, y: y_train}) \n",
    "            mse_valid = loss.eval(feed_dict={X: x_valid, y: y_valid}) \n",
    "            print('%.2f epochs: MSE train/valid = %.6f/%.6f'%(\n",
    "                iteration*batch_size/train_set_size, mse_train, mse_valid))\n",
    "\n",
    "    y_train_pred = sess.run(outputs, feed_dict={X: x_train})\n",
    "    y_valid_pred = sess.run(outputs, feed_dict={X: x_valid})\n",
    "    y_test_pred = sess.run(outputs, feed_dict={X: x_test})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cc863c4660d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m          y_test[:,ft], color='black', label='LSTM test target')\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m plt.plot(np.arange(y_train_pred.shape[0]),y_train_pred[:,ft], color='red',\n\u001b[0m\u001b[1;32m     17\u001b[0m          label='LSTM train prediction')\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_pred' is not defined"
     ]
    }
   ],
   "source": [
    "ft = 1 #  1 = close price\n",
    "\n",
    "## show predictions\n",
    "figLSTMPredict=plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]), y_train[:,ft], color='blue', label='LSTM train target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_valid.shape[0]), y_valid[:,ft],\n",
    "         color='gray', label='LSTM valid target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]+y_valid.shape[0],\n",
    "                   y_train.shape[0]+y_test.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='LSTM test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]),y_train_pred[:,ft], color='red',\n",
    "         label='LSTM train prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_valid_pred.shape[0]),\n",
    "         y_valid_pred[:,ft], color='orange', label='LSTM valid prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]+y_valid_pred.shape[0],\n",
    "                   y_train_pred.shape[0]+y_valid_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='LSTM test prediction')\n",
    "\n",
    "plt.title('past and future stock prices')\n",
    "plt.xlabel('Days (2015.01.02 ~ 2018.01.29)')\n",
    "plt.ylabel('normalized CGC stock price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='LSTM test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='LSTM test prediction')\n",
    "\n",
    "plt.title('future CGC stock prices')\n",
    "plt.xlabel('Days (from 2018.06.16 ~ 2018.11.08)')\n",
    "plt.ylabel('normalized CGC stock price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "figLSTMPredict.savefig('figLSTMPredict.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate pred return and actual return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Return= close yt+1 - close yt\n",
    "y_train_Close= y_train[:,0]\n",
    "y_train_pred_Close= y_train_pred[:,0]\n",
    "\n",
    "y_valid_Close= y_valid[:,0]\n",
    "y_valid_pred_Close= y_valid_pred[:,0]\n",
    "\n",
    "\n",
    "y_test_Close= y_test[:,0]\n",
    "y_test_pred_Close= y_test_pred[:,0]\n",
    "\n",
    "\n",
    "corr_price_development_train = np.sum(np.equal(np.sign(y_train_Close[1:]-y_train_Close[:-1]),\n",
    "            np.sign(y_train_pred_Close[1:]-y_train_pred_Close[:-1] )).astype(int)) / y_train.shape[0]\n",
    "\n",
    "corr_price_development_valid = np.sum(np.equal(np.sign(y_valid_Close[1:]-y_valid_Close[:-1]),\n",
    "            np.sign(y_valid_pred_Close[1:]-y_valid_pred_Close[:-1] )).astype(int)) / y_valid.shape[0]\n",
    "\n",
    "corr_price_development_test = np.sum(np.equal(np.sign(y_test_Close[1:]-y_test_Close[:-1]),\n",
    "            np.sign(y_test_pred_Close[1:]-y_test_pred_Close[:-1])).astype(int)) / y_test.shape[0]\n",
    "\n",
    "                                             \n",
    "print('correct sign prediction for current close - previous close price for train/valid/test: %.2f/%.2f/%.2f'%(\n",
    "    corr_price_development_train, corr_price_development_valid, corr_price_development_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM train MSE =  2.21865184847851e-05\n",
      "LSTM train RMSE =  0.0047102567323645\n",
      "LSTM train MAE =  0.002368585601864515\n",
      "LSTM valid MSE =  0.0002846010724005194\n",
      "LSTM valid RMSE =  0.016870123662869795\n",
      "LSTM valid MAE =  0.013351467266700133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#LSTM train\n",
    "error = []\n",
    "for i in range(len(y_train_Close)):\n",
    "    error.append(y_train_Close[i] - y_train_pred_Close[i])\n",
    " \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val)\n",
    "    absError.append(abs(val))\n",
    " \n",
    "print(\"LSTM train MSE = \", sum(squaredError) / len(squaredError))\n",
    "from math import sqrt\n",
    "print(\"LSTM train RMSE = \", sqrt(sum(squaredError) / len(squaredError)))\n",
    "print(\"LSTM train MAE = \", sum(absError) / len(absError))\n",
    "\n",
    "def mean_absolute_percentage_error(y_train_Close, y_train_pred_Close): \n",
    "    y_train_Close, y_train_pred_Close = np.array(y_train_Close), np.array(y_train_pred_Close)\n",
    "    return np.mean(np.abs((y_train_Close - y_train_pred_Close) / y_train_pred_Close)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(y_train_Close, y_train_pred_Close)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lSTM valid\n",
    "error = []\n",
    "for i in range(len(y_valid_Close)):\n",
    "    error.append(y_valid_Close[i] - y_valid_pred_Close[i])\n",
    " \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val)\n",
    "    absError.append(abs(val))\n",
    " \n",
    "print(\"LSTM valid MSE = \", sum(squaredError) / len(squaredError))\n",
    "from math import sqrt\n",
    "print(\"LSTM valid RMSE = \", sqrt(sum(squaredError) / len(squaredError)))\n",
    "print(\"LSTM valid MAE = \", sum(absError) / len(absError))\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_valid_Close, y_valid_pred_Close): \n",
    "    y_valid_Close, y_valid_pred_Close = np.array(y_valid_Close), np.array(y_valid_pred_Close)\n",
    "    return np.mean(np.abs((y_valid_Close - y_valid_pred_Close) / y_valid_pred_Close)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(y_valid_Close, y_valid_pred_Close)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM test MSE =  0.10912844334269989\n",
      "LSTM test RMSE =  0.33034594494665726\n",
      "LSTM testMAE =  0.2316874741968532\n"
     ]
    }
   ],
   "source": [
    "# LSTM test \n",
    "error = []\n",
    "for i in range(len(y_test_Close)):\n",
    "    error.append(y_test_Close[i] - y_test_pred_Close[i])\n",
    " \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val)\n",
    "    absError.append(abs(val))\n",
    "      \n",
    "print(\"LSTM test MSE = \", sum(squaredError) / len(squaredError))\n",
    "from math import sqrt\n",
    "print(\"LSTM test RMSE = \", sqrt(sum(squaredError) / len(squaredError)))\n",
    "print(\"LSTM testMAE = \", sum(absError) / len(absError))\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_test_Close, y_test_pred_Close): \n",
    "    y_test_Close, y_test_pred_Close = np.array(y_test_Close), np.array(y_test_pred_Close)\n",
    "    return np.mean(np.abs((y_test_Close - y_test_pred_Close) / y_test_pred_Close)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(y_test_Close, y_test_pred_Close)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading  Strategy profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action_list(y_test_pred_Close):    \n",
    "    a=[]\n",
    "    i=1\n",
    "    for i in range(96):\n",
    "        if y_test_pred_Close[i]> y_test_pred_Close[i-1]:\n",
    "            a.append(1)\n",
    "        else:\n",
    "            a.append(0)\n",
    "    return a\n",
    "\n",
    "S = action_list(y_test_pred_Close)\n",
    "#len(S)\n",
    "\n",
    "figLSTMReturn=plt.figure(figsize = (15,8))\n",
    "plt.plot(Return.cumsum(),'-',label='LSTM backtest result')\n",
    "#plt.plot(Return.cumsum(),'-',label='backtest result')\n",
    "plt.grid(1)\n",
    "\n",
    "plt.title('future CGC stock acumulative return')\n",
    "plt.xlabel('Days (from 2018.06.16 ~ 2018.11.08)')\n",
    "plt.ylabel('denormalized CGC stock price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "figLSTMReturn.savefig('LSTMReturn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y = y_test_pred_Close *(73.75 - 1.5)+ 1.5\n",
    "#Return= y *S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 GRU train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 epochs: MSE train/valid = 0.014708/0.179484\n",
      "5.00 epochs: MSE train/valid = 0.000197/0.000801\n",
      "10.00 epochs: MSE train/valid = 0.000131/0.000640\n",
      "15.00 epochs: MSE train/valid = 0.000114/0.000523\n",
      "20.00 epochs: MSE train/valid = 0.000098/0.000493\n",
      "25.00 epochs: MSE train/valid = 0.000106/0.000671\n",
      "30.00 epochs: MSE train/valid = 0.000101/0.000611\n",
      "35.00 epochs: MSE train/valid = 0.000082/0.000445\n",
      "40.00 epochs: MSE train/valid = 0.000086/0.000584\n",
      "45.00 epochs: MSE train/valid = 0.000079/0.000451\n",
      "50.00 epochs: MSE train/valid = 0.000074/0.000483\n",
      "55.00 epochs: MSE train/valid = 0.000078/0.000557\n",
      "60.00 epochs: MSE train/valid = 0.000069/0.000392\n",
      "65.00 epochs: MSE train/valid = 0.000069/0.000399\n",
      "70.00 epochs: MSE train/valid = 0.000065/0.000384\n",
      "75.00 epochs: MSE train/valid = 0.000073/0.000400\n",
      "80.00 epochs: MSE train/valid = 0.000081/0.000641\n",
      "85.00 epochs: MSE train/valid = 0.000091/0.000429\n",
      "90.00 epochs: MSE train/valid = 0.000066/0.000380\n",
      "95.00 epochs: MSE train/valid = 0.000063/0.000381\n",
      "100.00 epochs: MSE train/valid = 0.000065/0.000378\n",
      "105.00 epochs: MSE train/valid = 0.000063/0.000362\n",
      "110.00 epochs: MSE train/valid = 0.000065/0.000375\n",
      "115.00 epochs: MSE train/valid = 0.000078/0.000388\n",
      "120.00 epochs: MSE train/valid = 0.000074/0.000416\n",
      "125.00 epochs: MSE train/valid = 0.000063/0.000364\n",
      "130.00 epochs: MSE train/valid = 0.000061/0.000388\n",
      "135.00 epochs: MSE train/valid = 0.000076/0.000491\n",
      "140.00 epochs: MSE train/valid = 0.000096/0.000953\n",
      "145.00 epochs: MSE train/valid = 0.000066/0.000356\n",
      "150.00 epochs: MSE train/valid = 0.000099/0.000870\n",
      "155.00 epochs: MSE train/valid = 0.000062/0.000378\n",
      "160.00 epochs: MSE train/valid = 0.000069/0.000394\n",
      "165.00 epochs: MSE train/valid = 0.000065/0.000403\n",
      "170.00 epochs: MSE train/valid = 0.000063/0.000345\n",
      "175.00 epochs: MSE train/valid = 0.000069/0.000556\n",
      "180.00 epochs: MSE train/valid = 0.000061/0.000356\n",
      "185.00 epochs: MSE train/valid = 0.000080/0.000385\n",
      "190.00 epochs: MSE train/valid = 0.000064/0.000417\n",
      "195.00 epochs: MSE train/valid = 0.000061/0.000359\n",
      "200.00 epochs: MSE train/valid = 0.000061/0.000356\n",
      "205.00 epochs: MSE train/valid = 0.000076/0.000625\n",
      "210.00 epochs: MSE train/valid = 0.000071/0.000451\n",
      "215.00 epochs: MSE train/valid = 0.000060/0.000379\n",
      "220.00 epochs: MSE train/valid = 0.000071/0.000412\n",
      "225.00 epochs: MSE train/valid = 0.000061/0.000359\n",
      "230.00 epochs: MSE train/valid = 0.000065/0.000444\n",
      "235.00 epochs: MSE train/valid = 0.000077/0.000672\n",
      "240.00 epochs: MSE train/valid = 0.000069/0.000558\n",
      "245.00 epochs: MSE train/valid = 0.000060/0.000363\n",
      "250.00 epochs: MSE train/valid = 0.000068/0.000451\n",
      "255.00 epochs: MSE train/valid = 0.000063/0.000374\n",
      "260.00 epochs: MSE train/valid = 0.000066/0.000418\n",
      "265.00 epochs: MSE train/valid = 0.000060/0.000379\n",
      "270.00 epochs: MSE train/valid = 0.000060/0.000360\n",
      "275.00 epochs: MSE train/valid = 0.000077/0.000496\n",
      "280.00 epochs: MSE train/valid = 0.000094/0.000704\n",
      "285.00 epochs: MSE train/valid = 0.000062/0.000432\n",
      "290.00 epochs: MSE train/valid = 0.000060/0.000390\n",
      "295.00 epochs: MSE train/valid = 0.000068/0.000427\n",
      "300.00 epochs: MSE train/valid = 0.000064/0.000395\n",
      "305.00 epochs: MSE train/valid = 0.000062/0.000368\n",
      "310.00 epochs: MSE train/valid = 0.000060/0.000370\n",
      "315.00 epochs: MSE train/valid = 0.000062/0.000390\n",
      "320.00 epochs: MSE train/valid = 0.000069/0.000430\n",
      "325.00 epochs: MSE train/valid = 0.000080/0.000406\n",
      "330.00 epochs: MSE train/valid = 0.000058/0.000384\n",
      "335.00 epochs: MSE train/valid = 0.000061/0.000366\n",
      "340.00 epochs: MSE train/valid = 0.000070/0.000485\n",
      "345.00 epochs: MSE train/valid = 0.000125/0.000831\n",
      "350.00 epochs: MSE train/valid = 0.000060/0.000392\n",
      "355.00 epochs: MSE train/valid = 0.000060/0.000384\n",
      "360.00 epochs: MSE train/valid = 0.000068/0.000586\n",
      "365.00 epochs: MSE train/valid = 0.000060/0.000433\n",
      "370.00 epochs: MSE train/valid = 0.000060/0.000416\n",
      "375.00 epochs: MSE train/valid = 0.000060/0.000390\n",
      "380.00 epochs: MSE train/valid = 0.000062/0.000391\n",
      "385.00 epochs: MSE train/valid = 0.000060/0.000433\n",
      "390.00 epochs: MSE train/valid = 0.000062/0.000381\n",
      "395.00 epochs: MSE train/valid = 0.000064/0.000395\n",
      "400.00 epochs: MSE train/valid = 0.000063/0.000407\n",
      "405.00 epochs: MSE train/valid = 0.000059/0.000389\n",
      "410.00 epochs: MSE train/valid = 0.000063/0.000448\n",
      "415.00 epochs: MSE train/valid = 0.000083/0.000623\n",
      "420.00 epochs: MSE train/valid = 0.000058/0.000397\n",
      "425.00 epochs: MSE train/valid = 0.000067/0.000422\n",
      "430.00 epochs: MSE train/valid = 0.000062/0.000392\n",
      "435.00 epochs: MSE train/valid = 0.000062/0.000400\n",
      "440.00 epochs: MSE train/valid = 0.000125/0.001014\n",
      "445.00 epochs: MSE train/valid = 0.000071/0.000446\n",
      "450.00 epochs: MSE train/valid = 0.000063/0.000467\n",
      "455.00 epochs: MSE train/valid = 0.000071/0.000455\n",
      "460.00 epochs: MSE train/valid = 0.000059/0.000391\n",
      "465.00 epochs: MSE train/valid = 0.000061/0.000405\n",
      "470.00 epochs: MSE train/valid = 0.000092/0.000505\n",
      "475.00 epochs: MSE train/valid = 0.000066/0.000369\n",
      "480.00 epochs: MSE train/valid = 0.000102/0.001046\n",
      "485.00 epochs: MSE train/valid = 0.000076/0.000373\n",
      "490.00 epochs: MSE train/valid = 0.000071/0.000550\n",
      "495.00 epochs: MSE train/valid = 0.000081/0.000435\n",
      "500.00 epochs: MSE train/valid = 0.000065/0.000447\n",
      "505.00 epochs: MSE train/valid = 0.000102/0.000684\n",
      "510.00 epochs: MSE train/valid = 0.000058/0.000404\n",
      "515.00 epochs: MSE train/valid = 0.000073/0.000383\n",
      "520.00 epochs: MSE train/valid = 0.000059/0.000394\n",
      "525.00 epochs: MSE train/valid = 0.000069/0.000492\n",
      "530.00 epochs: MSE train/valid = 0.000062/0.000421\n",
      "535.00 epochs: MSE train/valid = 0.000058/0.000396\n",
      "540.00 epochs: MSE train/valid = 0.000065/0.000425\n",
      "545.00 epochs: MSE train/valid = 0.000061/0.000404\n",
      "550.00 epochs: MSE train/valid = 0.000059/0.000383\n",
      "555.00 epochs: MSE train/valid = 0.000077/0.000560\n",
      "560.00 epochs: MSE train/valid = 0.000060/0.000381\n",
      "565.00 epochs: MSE train/valid = 0.000065/0.000422\n",
      "570.00 epochs: MSE train/valid = 0.000061/0.000386\n",
      "575.00 epochs: MSE train/valid = 0.000068/0.000459\n",
      "580.00 epochs: MSE train/valid = 0.000060/0.000449\n",
      "585.00 epochs: MSE train/valid = 0.000059/0.000415\n",
      "590.00 epochs: MSE train/valid = 0.000063/0.000459\n",
      "595.00 epochs: MSE train/valid = 0.000063/0.000447\n",
      "600.00 epochs: MSE train/valid = 0.000059/0.000391\n",
      "605.00 epochs: MSE train/valid = 0.000064/0.000459\n",
      "610.00 epochs: MSE train/valid = 0.000065/0.000553\n",
      "615.00 epochs: MSE train/valid = 0.000059/0.000444\n",
      "620.00 epochs: MSE train/valid = 0.000062/0.000447\n",
      "625.00 epochs: MSE train/valid = 0.000063/0.000424\n",
      "630.00 epochs: MSE train/valid = 0.000065/0.000409\n",
      "635.00 epochs: MSE train/valid = 0.000062/0.000498\n",
      "640.00 epochs: MSE train/valid = 0.000057/0.000404\n",
      "645.00 epochs: MSE train/valid = 0.000065/0.000426\n",
      "650.00 epochs: MSE train/valid = 0.000059/0.000413\n",
      "655.00 epochs: MSE train/valid = 0.000072/0.000472\n",
      "660.00 epochs: MSE train/valid = 0.000078/0.000457\n",
      "665.00 epochs: MSE train/valid = 0.000059/0.000393\n",
      "670.00 epochs: MSE train/valid = 0.000057/0.000440\n",
      "675.00 epochs: MSE train/valid = 0.000094/0.000698\n",
      "680.00 epochs: MSE train/valid = 0.000059/0.000444\n",
      "685.00 epochs: MSE train/valid = 0.000067/0.000484\n",
      "690.00 epochs: MSE train/valid = 0.000094/0.000530\n",
      "695.00 epochs: MSE train/valid = 0.000070/0.000469\n",
      "700.00 epochs: MSE train/valid = 0.000057/0.000405\n",
      "705.00 epochs: MSE train/valid = 0.000096/0.000558\n",
      "710.00 epochs: MSE train/valid = 0.000057/0.000418\n",
      "715.00 epochs: MSE train/valid = 0.000077/0.000463\n",
      "720.00 epochs: MSE train/valid = 0.000064/0.000481\n",
      "725.00 epochs: MSE train/valid = 0.000064/0.000546\n",
      "730.00 epochs: MSE train/valid = 0.000060/0.000407\n",
      "735.00 epochs: MSE train/valid = 0.000057/0.000420\n",
      "740.00 epochs: MSE train/valid = 0.000056/0.000399\n",
      "745.00 epochs: MSE train/valid = 0.000063/0.000460\n",
      "750.00 epochs: MSE train/valid = 0.000059/0.000433\n",
      "755.00 epochs: MSE train/valid = 0.000057/0.000436\n",
      "760.00 epochs: MSE train/valid = 0.000068/0.000508\n",
      "765.00 epochs: MSE train/valid = 0.000065/0.000465\n",
      "770.00 epochs: MSE train/valid = 0.000059/0.000424\n",
      "775.00 epochs: MSE train/valid = 0.000058/0.000398\n",
      "780.00 epochs: MSE train/valid = 0.000066/0.000419\n",
      "785.00 epochs: MSE train/valid = 0.000056/0.000405\n",
      "790.00 epochs: MSE train/valid = 0.000069/0.000573\n",
      "795.00 epochs: MSE train/valid = 0.000068/0.000464\n",
      "800.00 epochs: MSE train/valid = 0.000056/0.000409\n",
      "805.00 epochs: MSE train/valid = 0.000073/0.000537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810.00 epochs: MSE train/valid = 0.000055/0.000417\n",
      "815.00 epochs: MSE train/valid = 0.000056/0.000409\n",
      "820.00 epochs: MSE train/valid = 0.000064/0.000543\n",
      "825.00 epochs: MSE train/valid = 0.000059/0.000439\n",
      "830.00 epochs: MSE train/valid = 0.000105/0.000463\n",
      "835.00 epochs: MSE train/valid = 0.000056/0.000417\n",
      "840.00 epochs: MSE train/valid = 0.000063/0.000476\n",
      "845.00 epochs: MSE train/valid = 0.000058/0.000441\n",
      "850.00 epochs: MSE train/valid = 0.000074/0.000426\n",
      "855.00 epochs: MSE train/valid = 0.000056/0.000444\n",
      "860.00 epochs: MSE train/valid = 0.000056/0.000432\n",
      "865.00 epochs: MSE train/valid = 0.000068/0.000442\n",
      "870.00 epochs: MSE train/valid = 0.000085/0.000603\n",
      "875.00 epochs: MSE train/valid = 0.000063/0.000491\n",
      "880.00 epochs: MSE train/valid = 0.000061/0.000504\n",
      "885.00 epochs: MSE train/valid = 0.000064/0.000449\n",
      "890.00 epochs: MSE train/valid = 0.000056/0.000435\n",
      "895.00 epochs: MSE train/valid = 0.000058/0.000439\n",
      "900.00 epochs: MSE train/valid = 0.000056/0.000440\n",
      "905.00 epochs: MSE train/valid = 0.000060/0.000516\n",
      "910.00 epochs: MSE train/valid = 0.000061/0.000484\n",
      "915.00 epochs: MSE train/valid = 0.000057/0.000438\n",
      "920.00 epochs: MSE train/valid = 0.000071/0.000623\n",
      "925.00 epochs: MSE train/valid = 0.000072/0.000425\n",
      "930.00 epochs: MSE train/valid = 0.000064/0.000500\n",
      "935.00 epochs: MSE train/valid = 0.000058/0.000414\n",
      "940.00 epochs: MSE train/valid = 0.000055/0.000407\n",
      "945.00 epochs: MSE train/valid = 0.000063/0.000437\n",
      "950.00 epochs: MSE train/valid = 0.000056/0.000406\n",
      "955.00 epochs: MSE train/valid = 0.000055/0.000415\n",
      "960.00 epochs: MSE train/valid = 0.000062/0.000502\n",
      "965.00 epochs: MSE train/valid = 0.000058/0.000420\n",
      "970.00 epochs: MSE train/valid = 0.000058/0.000452\n",
      "975.00 epochs: MSE train/valid = 0.000060/0.000564\n",
      "980.00 epochs: MSE train/valid = 0.000056/0.000496\n",
      "985.00 epochs: MSE train/valid = 0.000064/0.000467\n",
      "990.00 epochs: MSE train/valid = 0.000056/0.000416\n",
      "995.00 epochs: MSE train/valid = 0.000080/0.000483\n"
     ]
    }
   ],
   "source": [
    "## Basic Cell GRU in tensorflow\n",
    "\n",
    "index_in_epoch = 0;\n",
    "perm_array  = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(perm_array)\n",
    "\n",
    "# function to get the next batch\n",
    "def get_next_batch(batch_size):\n",
    "    global index_in_epoch, x_train, perm_array   \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > x_train.shape[0]:\n",
    "        np.random.shuffle(perm_array) # shuffle permutation array\n",
    "        start = 0 # start next epoch\n",
    "        index_in_epoch = batch_size\n",
    "        \n",
    "    end = index_in_epoch\n",
    "    return x_train[perm_array[start:end]], y_train[perm_array[start:end]]\n",
    "\n",
    "# parameters\n",
    "n_steps = seq_len-1 \n",
    "n_inputs = 9 \n",
    "n_neurons = 3 \n",
    "n_outputs = 9\n",
    "n_layers = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "n_epochs = 1000 \n",
    "train_set_size = x_train.shape[0]\n",
    "test_set_size = x_test.shape[0]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_outputs])\n",
    "\n",
    "\n",
    "# use GRU cell\n",
    "layers = [tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=tf.nn.leaky_relu)\n",
    "          for layer in range(n_layers)]\n",
    "                                                                     \n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) \n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "outputs = outputs[:,n_steps-1,:] # keep only last output of sequence\n",
    "                                              \n",
    "loss = tf.reduce_mean(tf.square(outputs - y)) # loss function = mean squared error \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n",
    "training_op = optimizer.minimize(loss)\n",
    "                                              \n",
    "# run graph\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for iteration in range(int(n_epochs*train_set_size/batch_size)):\n",
    "        x_batch, y_batch = get_next_batch(batch_size) # fetch the next training batch \n",
    "        sess.run(training_op, feed_dict={X: x_batch, y: y_batch}) \n",
    "        if iteration % int(5*train_set_size/batch_size) == 0:\n",
    "            mse_train = loss.eval(feed_dict={X: x_train, y: y_train}) \n",
    "            mse_valid = loss.eval(feed_dict={X: x_valid, y: y_valid}) \n",
    "            print('%.2f epochs: MSE train/valid = %.6f/%.6f'%(\n",
    "                iteration*batch_size/train_set_size, mse_train, mse_valid))\n",
    "\n",
    "    y_train_pred = sess.run(outputs, feed_dict={X: x_train})\n",
    "    y_valid_pred = sess.run(outputs, feed_dict={X: x_valid})\n",
    "    y_test_pred = sess.run(outputs, feed_dict={X: x_test})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 GRU prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ft = 1 # 1= close\n",
    "\n",
    "## show predictions\n",
    "figGRUPredict=plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]), y_train[:,ft], color='blue', label='train target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_valid.shape[0]), y_valid[:,ft],\n",
    "         color='gray', label='GRU valid target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]+y_valid.shape[0],\n",
    "                   y_train.shape[0]+y_test.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='GRU test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]),y_train_pred[:,ft], color='red',\n",
    "         label='GRU train prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_valid_pred.shape[0]),\n",
    "         y_valid_pred[:,ft], color='orange', label='GRU valid prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]+y_valid_pred.shape[0],\n",
    "                   y_train_pred.shape[0]+y_valid_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='GRU test prediction')\n",
    "\n",
    "plt.title('past and future stock prices')\n",
    "plt.xlabel('Days (2015.01.02 ~ 2018.01.29)')\n",
    "plt.ylabel('normalized CGC stock price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='GRU test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='GRU test prediction')\n",
    "\n",
    "plt.title('future CGC stock prices')\n",
    "plt.xlabel('Days (from 2018.06.16 ~ 2018.11.08)')\n",
    "plt.ylabel('normalized CGC stock price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "figGRUPredict.savefig('figGRUredict.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate GRU  CORR SIGN, MSE, RMSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct sign prediction for current close - previous close price for train/valid/test: 0.73/0.77/0.77\n"
     ]
    }
   ],
   "source": [
    "## Return= close yt+1 - close yt\n",
    "y_train_Close= y_train[:,0]\n",
    "y_train_pred_Close= y_train_pred[:,0]\n",
    "\n",
    "y_valid_Close= y_valid[:,0]\n",
    "y_valid_pred_Close= y_valid_pred[:,0]\n",
    "\n",
    "\n",
    "y_test_Close= y_test[:,0]\n",
    "y_test_pred_Close= y_test_pred[:,0]\n",
    "\n",
    "\n",
    "corr_price_development_train = np.sum(np.equal(np.sign(y_train_Close[1:]-y_train_Close[:-1]),\n",
    "            np.sign(y_train_pred_Close[1:]-y_train_pred_Close[:-1] )).astype(int)) / y_train.shape[0]\n",
    "\n",
    "corr_price_development_valid = np.sum(np.equal(np.sign(y_valid_Close[1:]-y_valid_Close[:-1]),\n",
    "            np.sign(y_valid_pred_Close[1:]-y_valid_pred_Close[:-1] )).astype(int)) / y_valid.shape[0]\n",
    "\n",
    "corr_price_development_test = np.sum(np.equal(np.sign(y_test_Close[1:]-y_test_Close[:-1]),\n",
    "            np.sign(y_test_pred_Close[1:]-y_test_pred_Close[:-1])).astype(int)) / y_test.shape[0]\n",
    "\n",
    "                                             \n",
    "print('correct sign prediction for current close - previous close price for train/valid/test: %.2f/%.2f/%.2f'%(\n",
    "    corr_price_development_train, corr_price_development_valid, corr_price_development_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU train MSE =  2.1649264592305696e-05\n",
      "GRU train RMSE =  0.004652877023122973\n",
      "GRU train MAE =  0.002853033846979559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.78529998707532"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train\n",
    "error = []\n",
    "for i in range(len(y_train_Close)):\n",
    "    error.append(y_train_Close[i] - y_train_pred_Close[i])\n",
    " \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val)\n",
    "    absError.append(abs(val))\n",
    " \n",
    "print(\"GRU train MSE = \", sum(squaredError) / len(squaredError))\n",
    "from math import sqrt\n",
    "print(\"GRU train RMSE = \", sqrt(sum(squaredError) / len(squaredError)))\n",
    "print(\"GRU train MAE = \", sum(absError) / len(absError))\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_train_Close, y_train_pred_Close): \n",
    "    y_train_Close, y_train_pred_Close = np.array(y_train_Close), np.array(y_train_pred_Close)\n",
    "    return np.mean(np.abs((y_train_Close - y_train_pred_Close) / y_train_pred_Close)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(y_train_Close, y_train_pred_Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU valid MSE =  0.0002474097618970175\n",
      "GRU valid RMSE =  0.015729264505914366\n",
      "GRU valid MAE =  0.01208074793866188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.923925181085303"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid\n",
    "error = []\n",
    "for i in range(len(y_valid_Close)):\n",
    "    error.append(y_valid_Close[i] - y_valid_pred_Close[i])\n",
    " \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val)\n",
    "    absError.append(abs(val))\n",
    " \n",
    "print(\"GRU valid MSE = \", sum(squaredError) / len(squaredError))\n",
    "from math import sqrt\n",
    "print(\"GRU valid RMSE = \", sqrt(sum(squaredError) / len(squaredError)))\n",
    "print(\"GRU valid MAE = \", sum(absError) / len(absError))\n",
    "\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_valid_Close, y_valid_pred_Close): \n",
    "    y_valid_Close, y_valid_pred_Close = np.array(y_valid_Close), np.array(y_valid_pred_Close)\n",
    "    return np.mean(np.abs((y_valid_Close - y_valid_pred_Close) / y_valid_pred_Close)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(y_valid_Close, y_valid_pred_Close)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU test MSE =  0.006623056631994501\n",
      "GRU test RMSE =  0.08138216409014018\n",
      "GRU testMAE =  0.0666953058824679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.31583134017066"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  test \n",
    "error = []\n",
    "for i in range(len(y_test_Close)):\n",
    "    error.append(y_test_Close[i] - y_test_pred_Close[i])\n",
    " \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val)\n",
    "    absError.append(abs(val))\n",
    "      \n",
    "print(\"GRU test MSE = \", sum(squaredError) / len(squaredError))\n",
    "from math import sqrt\n",
    "print(\"GRU test RMSE = \", sqrt(sum(squaredError) / len(squaredError)))\n",
    "print(\"GRU testMAE = \", sum(absError) / len(absError))\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_test_Close, y_test_pred_Close): \n",
    "    y_test_Close, y_test_pred_Close = np.array(y_test_Close), np.array(y_test_pred_Close)\n",
    "    return np.mean(np.abs((y_test_Close - y_test_pred_Close) / y_test_pred_Close)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(y_test_Close, y_test_pred_Close)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action_list(y_test_pred_Close):    \n",
    "    a=[]\n",
    "    i=1\n",
    "    for i in range(96):\n",
    "        if y_test_pred_Close[i]> y_test_pred_Close[i-1]:\n",
    "            a.append(1)\n",
    "        else:\n",
    "            a.append(0)\n",
    "    return a\n",
    "\n",
    "S = action_list(y_test_pred_Close)\n",
    "#len(S)\n",
    "\n",
    "y = y_test_pred_Close *(73.75 - 1.5)+ 1.5\n",
    "Return= y *S\n",
    "\n",
    "figGRUReturn=plt.figure(figsize = (15,8))\n",
    "plt.plot(Return.cumsum(),'-',label='GRU backtest result')\n",
    "#plt.plot(Return.cumsum(),'-',label='backtest result')\n",
    "plt.grid(1)\n",
    "\n",
    "plt.title('future CGC stock acumulative return')\n",
    "plt.xlabel('Days (from 2018.06.16 ~ 2018.11.08)')\n",
    "plt.ylabel('denormalized CGC stock price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "figGRUReturn.savefig('GRUReturn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
